version: '3.8'
services:
  postgres:
    image: artifacts.paycore.com/postgres:13
    container_name: airflow_postgres
    mem_limit: 2g
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data
      #- postgres_data:/var/lib/postgresql/data
    command: >
        postgres
        -c shared_buffers=1GB
        -c effective_cache_size=2GB
        -c work_mem=32MB
        -c maintenance_work_mem=1GB
        -c max_connections=100
        -c checkpoint_completion_target=0.9
        -c wal_buffers=16MB
        -c default_statistics_target=100
        -c random_page_cost=1.1
        -c max_worker_processes=8
        -c max_parallel_workers_per_gather=4
        -c max_parallel_workers=8
    healthcheck:  
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-init:
    image: artifacts.paycore.com/apache/airflow:2.7.2-python3.9.13-prod
    container_name: airflow_init
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      PYTHONPATH: /opt/airflow:/opt/airflow/projects/etl_base_project
    entrypoint: /bin/bash 
    command: 
      - -c
      - |
        airflow db init
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com || true
    volumes:
      - .:/opt/airflow
      - ./dags:/opt/airflow/dags


  airflow-webserver:
    image: artifacts.paycore.com/apache/airflow:2.7.2-python3.9.13-prod
    container_name: airflow_webserver
    mem_limit: 4g 
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      TZ: Europe/Istanbul
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__DEFAULT_TIMEZONE: Europe/Istanbul
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__WEBSERVER__DEFAULT_USER_USERNAME: admin
      AIRFLOW__WEBSERVER__DEFAULT_USER_PASSWORD: admin
      PYTHONPATH: /opt/airflow:/opt/airflow/projects/etl_base_project
      AIRFLOW__WEBSERVER__WORKERS: "9"
      AIRFLOW__WEBSERVER__WEB_SERVER_WORKER_TIMEOUT: 180
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"    
    ports:
      - "8080:8080"
    volumes:
      - .:/opt/airflow
      - ./dags:/opt/airflow/dags 
      - /var/run/docker.sock:/var/run/docker.sock
    command: webserver
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    shm_size: "2g"         # büyük DataFrame/log render vs. için faydalı

  airflow-scheduler:
    image: artifacts.paycore.com/apache/airflow:2.7.2-python3.9.13-prod
    container_name: airflow_scheduler
    mem_limit: 24g 
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      TZ: Europe/Istanbul
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__DEFAULT_TIMEZONE: Europe/Istanbul
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      PYTHONPATH: /opt/airflow:/opt/airflow/projects/etl_base_project
      # ---- ÖNEMLİ: Scheduler & LocalExecutor paralellik ayarları ----
      # Global eşzamanlı task limiti
      AIRFLOW__CORE__PARALLELISM: "16"
      # Bir DAG başına aktif task
      AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: "8"
      # Bir DAG başına aynı anda aktif dagrun
      AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: "2"
      # Default pool slotları (yoksa pool limitine takılırsınız)
      AIRFLOW__CORE__NON_POOLED_TASK_SLOT_COUNT: "16"
      # Dynamic task mapping ile ilgili pratik limit
      AIRFLOW__CORE__MAX_MAP_LENGTH: "100000"
      # Scheduler tuning
      AIRFLOW__SCHEDULER__PARSING_PROCESSES: "4"           # CPU çekirdeği kadar (örn 4)
      AIRFLOW__SCHEDULER__MAX_TIS_PER_QUERY: "256"         # DB’den alınan TI sayısı
      AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC: "5"     # 1 daha sık heartbeat yerine 5 daha stable
      AIRFLOW__SCHEDULER__JOB_HEARTBEAT_SEC: "15"  # ← YENİ (DNS hatası için)
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: "30"      # DAG tarama aralığı
      AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: "30"  # aynı dosyayı yeniden işlemeyi geciktirme
      AIRFLOW__SCHEDULER__USE_ROW_LEVEL_LOCKING: "True"    # yüksek eşzamanlılıkta faydalı
      AIRFLOW__SCHEDULER__MAX_DAGRUNS_TO_CREATE_PER_LOOP: "10"
      AIRFLOW__SCHEDULER__MAX_DAGRUNS_PER_LOOP_TO_SCHEDULE: "10"
      AIRFLOW__SCHEDULER__ORPHANED_TASKS_CHECK_INTERVAL: "300"
      AIRFLOW__LOGGING__LOG_RETENTION_DAYS: "7"
    volumes:
      - .:/opt/airflow
      - ./dags:/opt/airflow/dags
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    deploy:
      resources:
        limits:
          cpus: "7.0"      # scheduler’a CPU verin
          memory: 24g
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    shm_size: "4g"
    tmpfs:
      - /tmp:size=14g,noexec,nosuid,nodev  # SpooledTemporaryFile + COPY buffer için hızlı tmpfs


